{
    "model_id": "xlm-roberta-base",
    "dataset_id": "AmazonScience/massive",
    "dataset_configs": ["en-US"],
    "repository_id": "xlm_r-massive-joint_nlu",
    "filters": {
        "scenario": ["calendar"]
    },
    "trainer": {
        "repository_id": "xlm_r-massive-joint_nlu",
        "evaluation_strategy": "epoch",
        "learning_rate": 2e-5,
        "per_device_train_batch_size": 16,
        "per_device_eval_batch_size": 16,
        "num_train_epochs": 10,
        "weight_decay": 0.01
    },
    "data_collator": {
        "padding": true,
        "max_length": 512
    }
}
